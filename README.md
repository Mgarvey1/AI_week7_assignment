# AI Ethics Assignment: Designing Responsible and Fair AI Systems

## Overview
This project audits bias in the COMPAS recidivism dataset using IBM AI Fairness 360 (AIF360).  
It demonstrates fairness evaluation, bias mitigation via reweighing, and ethical reflection in AI system design.

## Contents
- `COMPAS_Fairness_Audit.ipynb` â€” main notebook with code, analysis, and graphs.
- Graphs:
  - **Graph 1:** Fairness metrics for COMPAS predictions.
  - **Graph 2:** Fairness metrics before vs after reweighing.
- Bonus: Ethical AI in healthcare policy example.

## Features
- Dataset audit for bias using AIF360.
- Logistic regression predictions on COMPAS dataset.
- Evaluation of fairness metrics (Disparate Impact, Equal Opportunity Difference, etc.).
- Reweighing bias mitigation.
- Ethical reflection and policy considerations.

## Usage
1. Open `COMPAS_Fairness_Audit.ipynb` in Google Colab or Jupyter Notebook.
2. Run all cells sequentially.
3. Replace placeholder graphs with generated visuals if necessary.
4. Review the bonus ethical guidelines cell for healthcare AI.

## Tools & Libraries
- Python 3.12
- Pandas, Numpy, Matplotlib
- IBM AI Fairness 360 (`aif360`)

## Notes
- Ensure the COMPAS dataset CSV is accessible in the notebook environment.
- The notebook is ready for submission; graphs are included as placeholders.
